{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2333429,"sourceType":"datasetVersion","datasetId":1408532}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 0. Kütüphane Tanımlaması","metadata":{}},{"cell_type":"markdown","source":"Bu adımda, görsel işleme, veri hazırlama, makine öğrenimi modeli oluşturma ve eğitim için gerekli olan kütüphaneler içe aktarılıyor. OpenCV (cv2) görselleri işlemek, NumPy veri yapıları ve matematiksel işlemler, scikit-learn veri ayırma ve düzenleme, TensorFlow Keras ise derin öğrenme modellerini oluşturmak ve eğitmek için kullanılıyor. Görsellerin yeniden boyutlandırılması, veri artırma (augmentation), sinir ağı katmanlarının oluşturulması ve modelin optimize edilmesi için gerekli tüm araçlar bu kütüphanelerle sağlanıyor.","metadata":{}},{"cell_type":"code","source":"# Gerekli kütüphaneleri içe aktar\nimport cv2\nimport os\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input, LeakyReLU, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.regularizers import l2\nfrom sklearn.utils import shuffle","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-22T20:26:39.216939Z","iopub.execute_input":"2024-12-22T20:26:39.217141Z","iopub.status.idle":"2024-12-22T20:26:47.597921Z","shell.execute_reply.started":"2024-12-22T20:26:39.217121Z","shell.execute_reply":"2024-12-22T20:26:47.597222Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## 1.Veriyi Okuma ","metadata":{}},{"cell_type":"markdown","source":"Veri setiyle çalışmak için gerekli dizinler ve parametreler tanımlanmıştır. Görsellerin bulunduğu ana dizin (data_dir) ve işlenmiş, manipüle edilmiş veya beyaz dengesi düzeltilmiş görseller için hedef dizinler belirlenmiştir. Ayrıca, üzerinde çalışılacak 10 hayvan sınıfı seçilmiş ve her sınıf için maksimum 650 görsel işleme alınacak şekilde sınırlandırılmıştır. Görsellerin boyutu 128x128 piksel olarak yeniden boyutlandırılacaktır. Bu ayarlar, veri işleme ve analiz adımlarını düzenlemek için temel yapı taşlarını oluşturur.","metadata":{}},{"cell_type":"code","source":"\n# Veri seti dizinleri\ndata_dir = \"/kaggle/input/animals-with-attributes-2/Animals_with_Attributes2/JPEGImages\"\noutput_dir = \"/kaggle/working/selected_animals_dataset\"\nprocessed_dir = \"/kaggle/working/processed_dataset\"\nmanipulated_dir = \"/kaggle/working/manipulated_images\"\nwb_dir = \"/kaggle/working/wb_corrected_images\"\n\n# Seçilen hayvan sınıfları ve parametreler\nselected_classes = [\n    \"collie\", \"dolphin\", \"elephant\", \"fox\", \"moose\", \n    \"rabbit\", \"sheep\", \"squirrel\", \"giant+panda\", \"polar+bear\"\n]\nmax_images_per_class = 650\nimage_size = (128, 128)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T20:26:47.598899Z","iopub.execute_input":"2024-12-22T20:26:47.599378Z","iopub.status.idle":"2024-12-22T20:26:47.603354Z","shell.execute_reply.started":"2024-12-22T20:26:47.599354Z","shell.execute_reply":"2024-12-22T20:26:47.602513Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## 1.Veriyi Okuma ve İşleme","metadata":{}},{"cell_type":"markdown","source":"çıktı dizinleri temizlenerek yeniden oluşturulmuş ve seçilen hayvan sınıflarındaki görseller işlenmiştir. Her sınıf için belirlenen maksimum görsel sayısı kadar görsel alınarak, 128x128 piksele yeniden boyutlandırılmış ve normalize edilmiştir (0-1 aralığına getirilmiştir). İşlenmiş görseller, ilgili sınıf isimlerine göre organize edilerek hedef dizine kaydedilmiştir. Bu işlem, veri setini model eğitimi için uygun hale getirmiştir.","metadata":{}},{"cell_type":"code","source":"# Çıktı dizinlerini temizle ve oluştur\nfor dir_path in [output_dir, processed_dir, manipulated_dir, wb_dir]:\n    if os.path.exists(dir_path):\n        shutil.rmtree(dir_path)\n    os.makedirs(dir_path)\n\n# Görselleri seç, yeniden boyutlandır ve normalize et\nfor animal_class in selected_classes:\n    class_path = os.path.join(data_dir, animal_class)\n    if os.path.exists(class_path):\n        images = sorted(os.listdir(class_path))[:max_images_per_class]\n        processed_class_path = os.path.join(processed_dir, animal_class)\n        os.makedirs(processed_class_path, exist_ok=True)\n\n        for image_name in images:\n            img_path = os.path.join(class_path, image_name)\n            img = cv2.imread(img_path)\n            if img is not None:\n                img_resized = cv2.resize(img, image_size)\n                img_normalized = img_resized / 255.0\n                processed_image_path = os.path.join(processed_class_path, image_name)\n                cv2.imwrite(processed_image_path, (img_normalized * 255).astype(np.uint8))\n\nprint(f\"Veri seti '{processed_dir}' dizininde işlenmiştir.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T20:26:47.604723Z","iopub.execute_input":"2024-12-22T20:26:47.604942Z","iopub.status.idle":"2024-12-22T20:28:27.578059Z","shell.execute_reply.started":"2024-12-22T20:26:47.604923Z","shell.execute_reply":"2024-12-22T20:28:27.577317Z"}},"outputs":[{"name":"stdout","text":"Veri seti '/kaggle/working/processed_dataset' dizininde işlenmiştir.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## 2. Görüntü Manipülasyonu ve Beyaz Dengesi Düzenleme Adımı\n\n\n\n\n\n","metadata":{}},{"cell_type":"markdown","source":"işlenmiş görseller üzerinde manipülasyon ve beyaz dengesi düzenleme işlemleri yapılmıştır. Manipülasyon fonksiyonu, kontrast ve parlaklığı artırarak görselleri manipüle edip belirlenen dizine kaydetmiştir. Ardından, beyaz dengesi fonksiyonu her bir görselin renk kanallarını ortalama gri seviyesine göre ayarlayarak beyaz dengesini düzenlemiş ve sonuçları ayrı bir dizine kaydetmiştir. Bu işlemler, görsellerin kalitesini artırarak model eğitimi için daha uygun hale getirilmesini sağlamıştır.","metadata":{}},{"cell_type":"code","source":"# Manipülasyon Fonksiyonu\ndef get_manipulated_images(input_dir, output_dir, brightness=1.5, contrast=1.2):\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    for class_name in os.listdir(input_dir):\n        class_path = os.path.join(input_dir, class_name)\n        output_class_path = os.path.join(output_dir, class_name)\n        os.makedirs(output_class_path, exist_ok=True)\n\n        for img_name in os.listdir(class_path):\n            img_path = os.path.join(class_path, img_name)\n            img = cv2.imread(img_path)\n            if img is not None:\n                manipulated_img = cv2.convertScaleAbs(img, alpha=contrast, beta=brightness * 50)\n                save_path = os.path.join(output_class_path, img_name)\n                cv2.imwrite(save_path, manipulated_img)\n\nget_manipulated_images(processed_dir, manipulated_dir)\nprint(f\"Manipüle edilmiş görüntüler '{manipulated_dir}' dizinine kaydedildi.\")\n\n# Beyaz Dengesi Fonksiyonu\ndef get_wb_images(input_dir, output_dir):\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    for class_name in os.listdir(input_dir):\n        class_path = os.path.join(input_dir, class_name)\n        output_class_path = os.path.join(output_dir, class_name)\n        os.makedirs(output_class_path, exist_ok=True)\n\n        for img_name in os.listdir(class_path):\n            img_path = os.path.join(class_path, img_name)\n            img = cv2.imread(img_path)\n            if img is not None:\n                avg_b, avg_g, avg_r = np.mean(img, axis=(0, 1))\n                avg_gray = (avg_b + avg_g + avg_r) / 3\n                img[:, :, 0] = np.clip(img[:, :, 0] * (avg_gray / avg_b), 0, 255)\n                img[:, :, 1] = np.clip(img[:, :, 1] * (avg_gray / avg_g), 0, 255)\n                img[:, :, 2] = np.clip(img[:, :, 2] * (avg_gray / avg_r), 0, 255)\n                save_path = os.path.join(output_class_path, img_name)\n                cv2.imwrite(save_path, img.astype(np.uint8))\n\nget_wb_images(manipulated_dir, wb_dir)\nprint(f\"Beyaz dengesi sağlanmış görüntüler '{wb_dir}' dizinine kaydedildi.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T20:28:27.579245Z","iopub.execute_input":"2024-12-22T20:28:27.579506Z","iopub.status.idle":"2024-12-22T20:28:37.491364Z","shell.execute_reply.started":"2024-12-22T20:28:27.579483Z","shell.execute_reply":"2024-12-22T20:28:37.490653Z"}},"outputs":[{"name":"stdout","text":"Manipüle edilmiş görüntüler '/kaggle/working/manipulated_images' dizinine kaydedildi.\nBeyaz dengesi sağlanmış görüntüler '/kaggle/working/wb_corrected_images' dizinine kaydedildi.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## 3. Görsellerin Yüklenmesi ve Etiketlenmesi","metadata":{}},{"cell_type":"markdown","source":" işlenmiş, manipüle edilmiş ve beyaz dengesi sağlanmış görseller belirlenen dizinlerden yüklenmiş ve sınıflarına göre etiketlenmiştir. Her görsel 0-1 aralığında normalize edilerek bir NumPy dizisine eklenmiş, etiketler ise sınıf adlarına karşılık gelen sayısal değerlerle eşleştirilmiştir. Bu işlem, model eğitimi için görsellerin ve etiketlerin organize bir şekilde hazırlanmasını sağlamıştır.","metadata":{}},{"cell_type":"code","source":"def load_images_from_directory(input_dir, class_names):\n    X, y = [], []\n    class_mapping = {cls: idx for idx, cls in enumerate(class_names)}\n\n    for class_name in class_names:\n        class_path = os.path.join(input_dir, class_name)\n        if os.path.exists(class_path):\n            images = sorted(os.listdir(class_path))\n            for img_name in images:\n                img_path = os.path.join(class_path, img_name)\n                img = cv2.imread(img_path)\n                if img is not None:\n                    X.append(img / 255.0)\n                    y.append(class_mapping[class_name])\n\n    return np.array(X), np.array(y)\n\n# Yükleme işlemi\nX_train, y_train = load_images_from_directory(processed_dir, selected_classes)\nX_manipulated_train, y_manipulated_train = load_images_from_directory(manipulated_dir, selected_classes)\nX_wb_train, y_wb_train = load_images_from_directory(wb_dir, selected_classes)\n\nprint(f\"Manipüle Edilmiş: {X_manipulated_train.shape}, Beyaz Dengeli: {X_wb_train.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T20:28:37.492156Z","iopub.execute_input":"2024-12-22T20:28:37.492382Z","iopub.status.idle":"2024-12-22T20:28:49.123551Z","shell.execute_reply.started":"2024-12-22T20:28:37.492360Z","shell.execute_reply":"2024-12-22T20:28:49.122588Z"}},"outputs":[{"name":"stdout","text":"Manipüle Edilmiş: (6500, 128, 128, 3), Beyaz Dengeli: (6500, 128, 128, 3)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## 4. Veri Birleştirme ve CNN Model Eğitimi","metadata":{}},{"cell_type":"markdown","source":"işlenmiş, manipüle edilmiş ve beyaz dengesi sağlanmış tüm görseller birleştirilmiş ve etiketler one-hot encoding formatına dönüştürülerek model eğitimi için hazırlanmıştır. Ardından, bir Convolutional Neural Network (CNN) modeli tanımlanmış ve optimize edilmiştir. Model, görsellerdeki özellikleri öğrenmek için evrişim, havuzlama, normalizasyon ve yoğun katmanlar içermektedir. Model, tümleştirilmiş veri üzerinde 20 dönem boyunca eğitilmiştir. Bu işlem, sınıflandırma performansını artırmak için farklı veri varyasyonlarından faydalanmayı amaçlamaktadır.","metadata":{}},{"cell_type":"code","source":"# Veri birleştirme\nX_combined_train = np.concatenate([X_train, X_manipulated_train, X_wb_train], axis=0)\ny_combined_train = np.concatenate([y_train, y_manipulated_train, y_wb_train], axis=0)\n\n# Etiketleri one-hot encoding\ny_combined_train_one_hot = to_categorical(y_combined_train, num_classes=len(selected_classes))\n\n# CNN Model\nmodel = Sequential([\n    Input(shape=(128, 128, 3)),\n    Conv2D(32, (3, 3)),\n    LeakyReLU(alpha=0.1),\n    BatchNormalization(),\n    MaxPooling2D((2, 2)),\n    Conv2D(64, (3, 3)),\n    LeakyReLU(alpha=0.1),\n    BatchNormalization(),\n    MaxPooling2D((2, 2)),\n    Conv2D(128, (3, 3)),\n    LeakyReLU(alpha=0.1),\n    BatchNormalization(),\n    MaxPooling2D((2, 2)),\n    Flatten(),\n    Dense(128, kernel_regularizer=l2(0.02)),\n    LeakyReLU(alpha=0.1),\n    Dropout(0.7),\n    Dense(len(selected_classes), activation='softmax')\n])\n\nmodel.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Eğitim\nhistory = model.fit(X_combined_train, y_combined_train_one_hot, epochs=20, batch_size=32)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T20:28:49.124475Z","iopub.execute_input":"2024-12-22T20:28:49.124846Z","iopub.status.idle":"2024-12-22T20:33:16.354428Z","shell.execute_reply.started":"2024-12-22T20:28:49.124809Z","shell.execute_reply":"2024-12-22T20:33:16.353401Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20\n\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.2873 - loss: 7.2661\nEpoch 2/20\n\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - accuracy: 0.4813 - loss: 5.1311\nEpoch 3/20\n\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - accuracy: 0.5912 - loss: 3.8039\nEpoch 4/20\n\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - accuracy: 0.6732 - loss: 2.9027\nEpoch 5/20\n\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - accuracy: 0.7327 - loss: 2.2810\nEpoch 6/20\n\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 19ms/step - accuracy: 0.7942 - loss: 1.8403\nEpoch 7/20\n\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 19ms/step - accuracy: 0.8364 - loss: 1.5527\nEpoch 8/20\n\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - accuracy: 0.8743 - loss: 1.3082\nEpoch 9/20\n\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - accuracy: 0.8819 - loss: 1.2118\nEpoch 10/20\n\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - accuracy: 0.8976 - loss: 1.1089\nEpoch 11/20\n\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - accuracy: 0.9069 - loss: 1.0582\nEpoch 12/20\n\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - accuracy: 0.9150 - loss: 1.0016\nEpoch 13/20\n\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - accuracy: 0.9230 - loss: 0.9491\nEpoch 14/20\n\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - accuracy: 0.9227 - loss: 0.9472\nEpoch 15/20\n\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - accuracy: 0.9230 - loss: 0.9347\nEpoch 16/20\n\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - accuracy: 0.9346 - loss: 0.9046\nEpoch 17/20\n\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - accuracy: 0.9429 - loss: 0.8690\nEpoch 18/20\n\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - accuracy: 0.9374 - loss: 0.8685\nEpoch 19/20\n\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - accuracy: 0.9378 - loss: 0.8804\nEpoch 20/20\n\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - accuracy: 0.9457 - loss: 0.8480\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## 4. Test Veri Değerlendirmesi ve Performans Karşılaştırması\n","metadata":{}},{"cell_type":"markdown","source":"Modelin performansını değerlendirmek için işlenmiş test veri seti yüklenmiş ve one-hot encoding ile etiketlenmiştir. Model, orijinal test verileri üzerinde değerlendirilerek kayıp ve doğruluk değerleri hesaplanmıştır. Ardından, test veri seti manipüle edilerek parlaklık artırılmış, döndürme işlemi uygulanmış ve yeniden ölçeklendirilmiştir. Manipüle edilmiş test veri seti üzerinde model yeniden değerlendirilerek doğruluk ve kayıp sonuçları raporlanmıştır.\n\nSon olarak, manipüle edilmiş veri setine beyaz dengesi işlemi uygulanmış ve model üzerinde aynı değerlendirme süreci tekrarlanmıştır. Bu işlemler, modelin veri manipülasyonlarına ve beyaz dengesi düzenlemelerine karşı performans değişimini ölçmeyi amaçlamaktadır. Elde edilen sonuçlar karşılaştırılarak modelin farklı veri varyasyonlarına ne kadar duyarlı olduğu analiz edilmiştir.","metadata":{}},{"cell_type":"code","source":"# Test verilerini yükleme\nX_test, y_test = load_images_from_directory(processed_dir, selected_classes)\ny_test_one_hot = to_categorical(y_test, num_classes=len(selected_classes))\n\n# Model değerlendirme\ntest_loss, test_accuracy = model.evaluate(X_test, y_test_one_hot, verbose=2)\nprint(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T20:33:16.355682Z","iopub.execute_input":"2024-12-22T20:33:16.356020Z","iopub.status.idle":"2024-12-22T20:33:25.661681Z","shell.execute_reply.started":"2024-12-22T20:33:16.355986Z","shell.execute_reply":"2024-12-22T20:33:25.660452Z"}},"outputs":[{"name":"stdout","text":"204/204 - 3s - 14ms/step - accuracy: 0.9957 - loss: 0.6951\nTest Loss: 0.695090651512146, Test Accuracy: 0.9956923127174377\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# 4. Manipüle Edilmiş Test Seti\n\ndef manipulate_images(X):\n    manipulated_images = []\n    for img in X:\n        img_8bit = (img * 255).astype(np.uint8)\n        manipulated = cv2.convertScaleAbs(img_8bit, alpha=2.0, beta=0)\n        manipulated = cv2.rotate(manipulated, cv2.ROTATE_90_CLOCKWISE)\n        manipulated_images.append(manipulated / 255.0)\n    return np.array(manipulated_images, dtype=np.float32)\n\nX_test_manipulated = manipulate_images(X_test)\nmanipulated_loss, manipulated_accuracy = model.evaluate(X_test_manipulated, y_test_one_hot, verbose=1)\nprint(f\"Manipüle Edilmiş Test Doğruluğu: {manipulated_accuracy * 100:.2f}%\")\n\n# 5. Beyaz Dengesi\n\ndef apply_white_balance(X):\n    wb_images = []\n    for img in X:\n        avg_b, avg_g, avg_r = cv2.mean(img)[:3]\n        avg_gray = (avg_b + avg_g + avg_r) / 3\n        img[:, :, 0] = np.clip(img[:, :, 0] * (avg_gray / avg_b), 0, 255)\n        img[:, :, 1] = np.clip(img[:, :, 1] * (avg_gray / avg_g), 0, 255)\n        img[:, :, 2] = np.clip(img[:, :, 2] * (avg_gray / avg_r), 0, 255)\n        wb_images.append(img / 255.0)\n    return np.array(wb_images, dtype=np.float32)\n\nX_test_wb = apply_white_balance(X_test_manipulated)\nwb_loss, wb_accuracy = model.evaluate(X_test_wb, y_test_one_hot, verbose=1)\nprint(f\"Beyaz Dengesi Test Doğruluğu: {wb_accuracy * 100:.2f}%\")\n\n# 6. Karşılaştırma ve Raporlama\nprint(\"Sonuçlar:\")\noriginal_loss, original_accuracy = model.evaluate(X_test, y_test_one_hot, verbose=1)\nprint(f\"Orijinal Test Seti Doğruluğu: {original_accuracy * 100:.2f}%\")\nprint(f\"Manipüle Test Seti Doğruluğu: {manipulated_accuracy * 100:.2f}%\")\nprint(f\"Beyaz Dengesi Uygulanmış Test Seti Doğruluğu: {wb_accuracy * 100:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T20:33:25.662426Z","iopub.execute_input":"2024-12-22T20:33:25.662654Z","iopub.status.idle":"2024-12-22T20:33:43.099344Z","shell.execute_reply.started":"2024-12-22T20:33:25.662634Z","shell.execute_reply":"2024-12-22T20:33:43.098628Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3905 - loss: 3.7628\nManipüle Edilmiş Test Doğruluğu: 36.17%\n\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0173 - loss: 4.1850\nBeyaz Dengesi Test Doğruluğu: 10.00%\nSonuçlar:\n\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9889 - loss: 0.7156\nOrijinal Test Seti Doğruluğu: 99.57%\nManipüle Test Seti Doğruluğu: 36.17%\nBeyaz Dengesi Uygulanmış Test Seti Doğruluğu: 10.00%\n","output_type":"stream"}],"execution_count":8}]}